{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import glob\n",
    "import importlib\n",
    "\n",
    "# Reset logging configuration\n",
    "logging.shutdown()\n",
    "importlib.reload(logging)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"C:/Users/91798/Desktop/ME36/source/log_file.txt\",\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "def extract_csv(file_path):\n",
    "    start_time = datetime.now()\n",
    "    logging.info(\"Extracting data from CSV file: %s\", file_path)\n",
    "    data = pd.read_csv(file_path)\n",
    "    logging.info(\"Finished extracting CSV file in %s\", datetime.now() - start_time)\n",
    "    return data.to_dict(orient='records')\n",
    "\n",
    "def extract_json(file_path):\n",
    "    start_time = datetime.now()\n",
    "    logging.info(\"Extracting data from JSON file: %s\", file_path)\n",
    "    data = pd.read_json(file_path, lines = True)\n",
    "    logging.info(\"Finished extracting JSON file in %s\", datetime.now() - start_time)\n",
    "    return data.to_dict(orient='records')\n",
    "\n",
    "def extract_xml(file_path):\n",
    "    start_time = datetime.now()\n",
    "    logging.info(\"Extracting data from XML file: %s\", file_path)\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    data = []\n",
    "    for child in root:\n",
    "        record = {elem.tag: elem.text for elem in child}\n",
    "        data.append(record)\n",
    "    logging.info(\"Finished extracting XML file in %s\", datetime.now() - start_time)\n",
    "    return data\n",
    "\n",
    "def extract_files(folder_path):\n",
    "    start_time = datetime.now()\n",
    "    logging.info(\"Extracting data from files in folder: %s\", folder_path)\n",
    "    combined_data = []\n",
    "    for file_path in glob.glob(f\"{folder_path}/*\"):\n",
    "        if file_path.endswith('.csv'):\n",
    "            combined_data.extend(extract_csv(file_path))\n",
    "        elif file_path.endswith('.json'):\n",
    "            combined_data.extend(extract_json(file_path))\n",
    "        elif file_path.endswith('.xml'):\n",
    "            combined_data.extend(extract_xml(file_path))\n",
    "    \n",
    "    #combined_data = pd.DataFrame(combined_data).drop_duplicates().to_dict(orient='records')\n",
    "    logging.info(\"Finished extracting all files in %s\", datetime.now() - start_time)\n",
    "    return combined_data\n",
    "\n",
    "def transform(data):\n",
    "    start_time = datetime.now()\n",
    "    logging.info(\"Transforming data\")\n",
    "    transformed_data = []\n",
    "    for record in data:\n",
    "        transformed_record = {}\n",
    "        for key, value in record.items():\n",
    "            # Convert heights from inches to meters\n",
    "            if key == 'height':\n",
    "                transformed_record[key] = float(value) * 0.0254  # Convert inches to meters\n",
    "            # Convert weights from pounds to kilograms\n",
    "            elif key == 'weight':\n",
    "                transformed_record[key] = float(value) * 0.453592  # Convert pounds to kilograms\n",
    "            else:\n",
    "                transformed_record[key] = value\n",
    "        transformed_data.append(transformed_record)\n",
    "    logging.info(\"Finished transforming data in %s\", datetime.now() - start_time)\n",
    "    return transformed_data\n",
    "\n",
    "def load_csv(data, output_file):\n",
    "    start_time = datetime.now()\n",
    "    logging.info(\"Loading data into CSV file: %s\", output_file)\n",
    "    if not data:\n",
    "        logging.warning(\"No data to load\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    logging.info(\"Data successfully loaded into %s in %s\", output_file, datetime.now() - start_time)\n",
    "\n",
    "def etl_pipeline(folder_path, output_file):\n",
    "    logging.info(\"Starting ETL pipeline\")\n",
    "\n",
    "    # Extract phase\n",
    "    combined_data = extract_files(folder_path)\n",
    "\n",
    "    # Transform phase\n",
    "    transformed_data = transform(combined_data)\n",
    "\n",
    "    # Load phase\n",
    "    load_csv(transformed_data, output_file)\n",
    "\n",
    "    logging.info(\"ETL pipeline completed successfully\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    etl_pipeline(\n",
    "        folder_path=\"C:/Users/91798/Desktop/ME36/source\",\n",
    "        output_file=\"C:/Users/91798/Desktop/ME36/source/transformed_data.csv\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
